{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3983a6",
   "metadata": {},
   "source": [
    "Loan Eligibility Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using Pandas, numpy, pandas, seaborn, and matplotlib.pyplot library (data analysis and visualization)\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('LoanApprovalPrediction.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f52b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the information about the LoanApprovalPrediction.csv dataset.\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing by checking the count of the missing values in the LoanApprovalPrediction.csv dataset.\n",
    "\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the total number of the dataset 'data'\n",
    "\n",
    "data.Loan_ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the Loan_ID contains Duplicate Values\n",
    "\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop and remove the Loan_ID column from the DataFrame\n",
    "\n",
    "data.drop(['Loan_ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8bb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the total number of missing values in a Pandas DataFrame named 'data'.\n",
    "\n",
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9465ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the Null Values of the variables\n",
    "\n",
    "\n",
    "# Fill the categorical values with the mode\n",
    "\n",
    "data['Dependents'] = data['Dependents'].fillna(data['Dependents'].mode()[0])\n",
    "\n",
    "# Fill the missing values with the mean starting with Loan Amount\n",
    "\n",
    "data['LoanAmount'] = data['LoanAmount'].fillna(data['LoanAmount'].mean())\n",
    "\n",
    "# Fill the missing values in Loan Amount Term \n",
    "\n",
    "data['Loan_Amount_Term'] = data['Loan_Amount_Term'].fillna(data['Loan_Amount_Term'].mean())\n",
    "\n",
    "# Fill the missing values in Credit History \n",
    "\n",
    "data['Credit_History'] = data.Credit_History.fillna(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd222d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet that maps the values of a column named \"Gender\" in a Pandas DataFrame named data from string values to numerical values.\n",
    "\n",
    "data.Gender = data.Gender.map({'Male': 0, 'Female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Seaborn library to create a countplot visualization of the distribution of a variable (Gender)\n",
    "\n",
    "sns.countplot(data=data,x='Gender' ,hue='Married')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of a variable (Dependents)\n",
    "\n",
    "sns.countplot(data=data,x='Dependents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c558f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of a variable (Education)\n",
    "\n",
    "sns.countplot(data=data, x='Education')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f67bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of loan Approval status for each category of the variable (Married).\n",
    "\n",
    "sns.countplot(data=data,x='Loan_Status',hue='Married')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b606d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of a variable (Self_Employed)\n",
    "\n",
    "sns.countplot(data=data,x='Self_Employed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the index of the DataFrame 'Data'.\n",
    "\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a1da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column to DataFrame 'Data' called 'Total_Income', which is calculated by summing the 'ApplicantIncome' and 'CoapplicantIncome' columns.\n",
    "\n",
    "data['Total_Income'] = data['ApplicantIncome'] + data['CoapplicantIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of a variable (Total_Income)\n",
    "\n",
    "sns.displot(data=data, x='Total_Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that is a copy of the original one 'Data'.\n",
    "# In case the numeric values skewed - log the data \n",
    "\n",
    "model_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d957c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the impact of extreme values and make the data more normally distributed\n",
    "\n",
    "model_data['Total_Income'] = np.log(model_data['Total_Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3748c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of a variable (Total_Income) of model_data set\n",
    "\n",
    "sns.displot(data=model_data, x='Total_Income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20715f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the column labels for the 'model_data' DataFrame and variables included in the dataset.\n",
    "\n",
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the impact of extreme values and make the data more normally distributed\n",
    "# Create a countplot visualization of the distribution of a variable (LoanAmount) of model_data set\n",
    "\n",
    "\n",
    "model_data['LoanAmount'] = np.log(model_data['LoanAmount'])\n",
    "sns.displot(data=model_data, x='LoanAmount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying the different loan terms that are available in the 'model_data'\n",
    "\n",
    "model_data['Loan_Amount_Term'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0192e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of a variable (Loan_Amount_Term) of model_data set\n",
    "\n",
    "sns.displot(data=model_data,x='Loan_Amount_Term')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the impact of extreme values and make the data more normally distributed\n",
    "# Create a countplot visualization of the distribution of a variable (Loan_Amount_Term) of model_data set\n",
    "\n",
    "\n",
    "model_data['Loan_Amount_Term'] = np.log(model_data['Loan_Amount_Term'])\n",
    "sns.displot(data=model_data, x='Loan_Amount_Term')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves all unique values in that variable 'Credit_History' column.\n",
    "# Return an array containing [0, 1].\n",
    "\n",
    "model_data['Credit_History'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068ae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of a variable (Credit_History) of model_data set\n",
    "\n",
    "sns.countplot(data=model_data, x='Credit_History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a countplot visualization of the distribution of a variable (Property Area)\n",
    "\n",
    "sns.countplot(data=data,x='Property_Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421341d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap visualization of a correlation matrix.\n",
    "\n",
    "sns.heatmap(data.corr(), cmap='BuPu', annot=True)\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables in the DataFrame will have been replaced with integer codes\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "obj = (data.dtypes == 'object')\n",
    "for col in list(obj[obj].index):\n",
    "    data[col] = label_encoder.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac650ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the missing values in a Pandas DataFrame named data with the mean value of each column.\n",
    "\n",
    "for col in data.columns:\n",
    "    data[col] = data[col].fillna(data[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc816808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares the data for a supervised machine learning task by separating the input features and the target variable in a Pandas DataFrame named data.\n",
    "\n",
    "x = data.drop(['Loan_Status'], axis=1)\n",
    "y = data.Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data into a training set and a testing set and 30% of the data will be used for testing and 70% will be used for training.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=7)\n",
    "\n",
    "\n",
    "print(\"Number of Original Data:\", model_data.shape[0])\n",
    "print(\"Number of Original Variable Data:\", model_data.shape[1])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Training Data:\", x_train.shape[0])\n",
    "print(\"Variables of Training Data:\", x_train.shape[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Testing Data:\", x_test.shape[0])\n",
    "print(\"Variables of Testing Data:\", x_test.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccbbc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trains and evaluates multiple machine learning models including Logistic Regression, Decision Tree Classifier, and Random Forest Classifier. on a dataset using cross-validation.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Define the models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression(max_iter=1000)))\n",
    "models.append(('Decision Tree Classifier', DecisionTreeClassifier()))\n",
    "models.append(('Random Forest Classifier', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "def modeling(model):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted') * 100\n",
    "    prec = precision_score(y_test, y_pred, average='weighted') * 100\n",
    "    rec = recall_score(y_test, y_pred, average='weighted') * 100\n",
    "    return acc, f1, prec, rec\n",
    "    \n",
    "    \n",
    "# Evaluate the machine learning models    \n",
    "results = []\n",
    "for name, model in models:\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted') * 100\n",
    "    prec = precision_score(y_test, y_pred, average='weighted') * 100\n",
    "    rec = recall_score(y_test, y_pred, average='weighted') * 100\n",
    "    results.append([name, acc, f1, prec, rec])\n",
    "\n",
    "    \n",
    "# Print the results in a table\n",
    "headers = ['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall']\n",
    "table = tabulate(results, headers=headers, tablefmt='orgtbl')\n",
    "print(table) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3c3d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
